{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import cv2\n",
    "from PIL import Image \n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "https://www.oreilly.com/library/view/ai-and-machine/9781492078180/ch04.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the first method\n",
    "(train_dataset, test_dataset), dataset_info = tfds.load('mnist',\n",
    "                                                        split=[\"train\",\"test\"],\n",
    "                                                        with_info=True,\n",
    "                                                        shuffle_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sample in train_dataset.take(1): #as the take number increases (from 2 to 5), the last bbox related to the last images are shown. \n",
    "    image = sample[\"image\"]\n",
    "    label = sample[\"label\"]\n",
    "    print(label)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second method\n",
    "#/home/abaygi/tensorflow_datasets/mnist/3.0.1\n",
    "(train_dataset, test_dataset), dataset_info = tfds.load(\"mnist\", \n",
    "                                                        split=[\"train\", \"test\"], \n",
    "                                                        with_info=True, \n",
    "                                                        shuffle_files=True, \n",
    "                                                        batch_size=-1, \n",
    "                                                        as_supervised=True)\n",
    "\n",
    "#(training_images, training_labels), (test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images, training_labels = tfds.as_numpy(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = tfds.as_numpy(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = tfds.load('mnist', split='train', shuffle_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(60000, 28, 28, 1), dtype=uint8, numpy=\n",
       " array([[[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       " \n",
       " \n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       " \n",
       " \n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       " \n",
       " \n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       " \n",
       " \n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]]], dtype=uint8)>,\n",
       " <tf.Tensor: shape=(60000,), dtype=int64, numpy=array([4, 1, 0, ..., 6, 1, 5])>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f64cc7af730>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(training_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "In order to use the pre-trained model introduced later in the tutorial, we will need to convert each image into a size of at least (75, 75, 3). Due to the limited RAM, we will use the minimum size. Note that we also have to include three channels instead of just 1 (just copy the same channel 3 times) to make use of the pre-trained weights.\n",
    "\n",
    "https://www.kaggle.com/saumandas/intro-to-transfer-learning-with-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "\n",
    "def change_size(image):\n",
    "    img = array_to_img(image, scale=False) #returns PIL Image\n",
    "    img = img.resize((75, 75)) #resize image\n",
    "    img = img.convert(mode='RGB') #makes 3 channels\n",
    "    arr = img_to_array(img) #convert back to array\n",
    "    return arr.astype(np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images_75 = [change_size(img) for img in training_images[:10000]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images_75 = np.array(training_images_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f64cc850e50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(training_images_75[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "Data augmentation is one of the most fundamental and useful strategy when dealing with images. It becomes especially useful if we have few images. This is not the case with this dataset, but it will still help anyway. Fortunately, ImageDataGenerator from keras makes it extremely simple to apply these augmentations. However, it is important to be careful when deciding which augmentations to apply.\n",
    "\n",
    "https://www.kaggle.com/saumandas/intro-to-transfer-learning-with-mnist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rescale=1./255, #easier for network to interpret numbers in range [0,1]\n",
    "                              zoom_range=0.1,\n",
    "                              width_shift_range=0.2,\n",
    "                              height_shift_range=0.2,\n",
    "                              validation_split=0.2) # 80/20 train/val split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dealing with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.keras.utils.to_categorical(training_labels[:10000]) # one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 75, 75, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_images_75.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = image_gen.flow(training_images_75, \n",
    "                                 y,\n",
    "                                batch_size=32,\n",
    "                                shuffle=True,\n",
    "                                subset='training',\n",
    "                                seed=42)\n",
    "valid_generator = image_gen.flow(training_images_75,\n",
    "                                 y,\n",
    "                                batch_size=16,\n",
    "                                shuffle=True,\n",
    "                                subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "\n",
    "Many features in general images are common and it is not worth starting to train from scratch. Usually the beginning layers in convolutional neural networks identify extremely basic features such as vertical and horizontal lines. This is what forms the backbone of tranfer learning. Using other peoples models, which have been trained on lots of data and are capable of identifying simple features, to fit your own data.\n",
    "\n",
    "Imagenet\n",
    "\n",
    "Imagenet is one of the largest image databases in the world! Every year, they host a competition known as the Imagenet Large Scale Visual Recognition Challenge (ILSVRC), where scientists from all over the world compete to create the best model. A couple years back, a group of researchers came up with the ResNet50, and now it's available to everyone! Learn more about the model here: resnet50 info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shape_size for ResNet50\n",
    "In practice, it is best to use this model with image size (224, 224, 3) since the original model was trained with that size. However, for the purpose of this tutorial (75, 75, 3) will also work. Note that we specified the weights as 'imagenet'. This will automatically load those pretrained weights into the model. If we do not specify, the weights will be initialized randomly and we would be starting from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base model\n",
    "base_model = ResNet50(input_shape=(75, 75, 3), \n",
    "                 include_top = False, \n",
    "                 weights = \"imagenet\")\n",
    "# Freeze base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new model on top.\n",
    "inputs = keras.Input(shape=(75, 75, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model(inputs, training=False)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 75, 75, 3)]       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Model)             (None, 3, 3, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               2359424   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 25,948,426\n",
      "Trainable params: 2,360,714\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "250/250 [==============================] - 267s 1s/step - loss: 1.2564 - accuracy: 0.6467 - val_loss: 1.1217 - val_accuracy: 0.6835\n",
      "Epoch 2/3\n",
      "250/250 [==============================] - 264s 1s/step - loss: 1.0260 - accuracy: 0.7166 - val_loss: 0.9384 - val_accuracy: 0.7290\n",
      "Epoch 3/3\n",
      "250/250 [==============================] - 261s 1s/step - loss: 0.8991 - accuracy: 0.7504 - val_loss: 0.8242 - val_accuracy: 0.7665\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                   validation_data=valid_generator, \n",
    "                   epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
